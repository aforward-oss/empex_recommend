# Saving a Model

```elixir
Mix.install([
  {:scholar, "~> 0.1"},
  {:nx, "~> 0.5"}
])

alias Scholar.Linear.LinearRegression, as: LR
```

## Build the Model

We will use our Pizzeria problem to estimate the number of pizza doughs to prepare.

```elixir
{features, label} = {
  Nx.stack([12, 20, 18, 30, 24]) |> Nx.stack(axis: -1),
  Nx.tensor([36, 72, 68, 82, 75])
}

model = LR.fit(features, label)
```

## Save The Model

Great, so now we want to save this model for re-use.  For that, we reach into Axom (I hope).

```elixir
model
|> Nx.serialize()
|> then(&File.write!("pizzeria.nx", &1))
```

## Load The Model

Let's reload the model and run our predictions.

```elixir
model = File.read!("pizzeria.nx") |> Nx.deserialize()
```

## Run the model

Now that the model is loaded back into Elixir, we can run the model and predict the outcome of the number of pizza doughs to create.

```elixir
LR.predict(model, Nx.tensor([15]))
|> Nx.to_number()
|> Float.round(0)
```

## More Generic Model Runner

As we are using scholar directly, instead of a neural network (aka Axon), we _could_ assume the model, but it is better to assume the method _predict_.

```elixir
for num_resi <- [5, 10, 15, 20, 25, 30, 35, 40] do
  num_doughs =
    apply(model.__struct__, :predict, [model, Nx.tensor([num_resi])])
    |> Nx.to_number()
    |> Float.round(0)

  IO.puts("With #{num_resi} reseravations  we should make #{num_doughs} pizza doughs")
  num_doughs
end
```

## Add To Project

You can create a Predictor within your application that encapsulates the above.

```elixir
defmodule Pizzeria do
  @model File.read!("pizzeria.nx") |> Nx.deserialize()

  def num_doughs(num_resi) do
    apply(@model.__struct__, :predict, [@model, Nx.tensor([num_resi])])
    |> Nx.to_number()
    |> Float.round(0)
  end
end

for num_resi <- [5, 10, 15, 20, 25, 30, 35, 40] do
  num_doughs = Pizzeria.num_doughs(num_resi)
  IO.puts("With #{num_resi} reseravations  we should make #{num_doughs} pizza doughs")
  num_doughs
end
```
