# Hand Written Numbers

```elixir
Mix.install([
  {:nx, "~> 0.5"},
  {:scidata, "~> 0.1"}
])
```

## Our Tensor helper (Tx)

A few things that I didn't see a _nice_ way to handle, I put into a `Tx` helper (for Tensor Nx helper).

```elixir
defmodule Tx do
  def one_hot_encode(tensor, set) do
    Nx.equal(tensor, Nx.tensor(set))
  end

  def split(tensor, train_ratio) do
    {rows, _cols} = Nx.shape(tensor)
    split_index = trunc(rows * train_ratio)

    {
      Nx.slice(tensor, {0, 0}, {split_index, -1}),
      Nx.slice(tensor, {split_index, 0}, {-1, -1})
    }
  end
end
```

## Split Training From Testing

To take your _ready_ tensor, you can split it into two sets,one for training and one for testing based on a %

```elixir
data = Nx.tensor([9, 5, 4, 1, 3, 5, 4, 3, 2, 4])
{train, test} = Tx.split(data, 0.8)
```

### One Hot Encode

To create a one_hot_encode, we load the labels, create the set of valid values and then create an equivalence using `Nx.equal`

```elixir
data = Nx.tensor([9, 3, 3, 5, 1]) |> Nx.new_axis(-1)
Tx.one_hot_encode(data, [1, 3, 5, 7, 9])
```

If you had multiple labels, then you could _one hot_ encode them too.

```elixir
data = Nx.tensor([[9, 1, 3], [1, 3, 5]]) |> Nx.new_axis(-1)
Tx.one_hot_encode(data, [1, 3, 5, 7, 9])
```

## Download Images

Scidata provides a convenient mechanism to download popular data sets.  Let's grab [MNSIT](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) database using [Scidata.MNIST.download()](https://github.com/elixir-nx/scidata/blob/master/lib/scidata/mnist.ex).  Note that it splits the images from the labels.

```elixir
{images, labels} = Scidata.MNIST.download()
```

### Prepare Features

Within each dataset, we have the _binary_ data, the image types, and the _shape_ of the data (from this we we want the number of images in the dataset, which is 60k).

```elixir
{bin, type, shape} = images
num_features = 28 * 28
dataset_size = elem(shape, 0)
{dataset_size, num_features}
```

We take our 28x28 image and _flatten_ it into 1-dimenasional array of 784.

```elixir
bias = Nx.broadcast(1, {dataset_size, 1})

tensor =
  bin
  |> Nx.from_binary(type)
  |> Nx.divide(255.0)
  |> Nx.reshape({dataset_size, num_features})

{train_features, test_features} =
  [bias, tensor]
  |> Nx.concatenate(axis: 1)
  |> Nx.to_batched(32)
  |> Enum.split(1750)
```

### Prepare Labels

The labels are 0 to 9.  Let's read them in

```elixir
{bin, type, _} = labels
num_train = 45000
num_rows = 60000

{train_labels, test_labels} =
  bin
  |> Nx.from_binary(type)
  |> Nx.new_axis(-1)
  |> Nx.equal(Nx.tensor(Enum.to_list(0..9)))
```

## Let's build a classifier for our data

```elixir
# defmodule Classifier do
#   def train(train_features, _train_labels, _test_features, _test_labels, _opts) do
#     h Nx.shape()
#     # Nx.broadcast(0, Nx.shape(train_features))
#   end
# end

# w = Classifier.train(train_features, train_labels, test_features, test_labels, iterations: 200, lr: 0.0005)
Nx.join()
```
